{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CatvsDog_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dn-6c02VmqiN",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIABnfrmmKkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "692b47de-212e-4ed4-f1ae-fe0651ce5541"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-19 12:09:42--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  81.0MB/s    in 1.0s    \n",
            "\n",
            "2020-08-19 12:09:44 (81.0 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3sd9dQWa23aj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "e5ccb3ec-1469-469e-e017-df290327a9d5"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-19 12:10:19--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.78.216.154, 2600:1417:76:586::e59, 2600:1417:76:58e::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.78.216.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.68M  99.4MB/s    in 7.4s    \n",
            "\n",
            "2020-08-19 12:10:27 (106 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-QkLjxpmyK2",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    \n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zvSODo0f9LaU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "f55f54fc-feef-44da-8c25-5254960f2dd9"
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "\n",
        "    dataset = []\n",
        "    \n",
        "    for unitData in os.listdir(SOURCE):\n",
        "        data = SOURCE + unitData\n",
        "        if (os.path.getsize(data) > 0):\n",
        "            dataset.append(unitData)\n",
        "        else:\n",
        "            print('Skipped ' + unitData)\n",
        "            print('Invalid file size! i.e Zero length.')\n",
        "    \n",
        "    train_data_length = int(len(dataset) * SPLIT_SIZE)\n",
        "    test_data_length = int(len(dataset) - train_data_length)\n",
        "    shuffled_set = random.sample(dataset, len(dataset))\n",
        "    train_set = shuffled_set[0:train_data_length]\n",
        "    test_set = shuffled_set[-test_data_length:]\n",
        "    \n",
        "    for unitData in train_set:\n",
        "        temp_train_data = SOURCE + unitData\n",
        "        final_train_data = TRAINING + unitData\n",
        "        copyfile(temp_train_data, final_train_data)\n",
        "    \n",
        "    for unitData in test_set:\n",
        "        temp_test_data = SOURCE + unitData\n",
        "        final_test_data = TESTING + unitData\n",
        "        copyfile(temp_train_data, final_test_data)\n",
        "\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipped 666.jpg\n",
            "Invalid file size! i.e Zero length.\n",
            "Skipped 11702.jpg\n",
            "Invalid file size! i.e Zero length.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgfB6bSlSUsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    if (logs.get('accuracy')>0.99):\n",
        "      print(\"Reaches 99% accuracy. Cancelling training\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-BQrav4anTmj",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense( 1 , activation = 'sigmoid')(x)\n",
        "\n",
        "model = Model( pre_trained_model.input , x)\n",
        "\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mlNjoJ5D61N6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "30424bc0-71be-45b8-88a2-d38d25852bc3"
      },
      "source": [
        "TRAINING_DIR = '/tmp/cats-v-dogs/training'\n",
        "train_datagen = ImageDataGenerator( rescale = 1/255,\n",
        "                                  rotation_range = 40,\n",
        "                                   width_shift_range= 0.2,\n",
        "                                   height_shift_range= 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode = 'nearest'\n",
        "                                  \n",
        "                                  )\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "TRAINING_DIR , batch_size = 20 , class_mode = 'binary' , target_size = (150,150))\n",
        "\n",
        "VALIDATION_DIR = '/tmp/cats-v-dogs/testing'\n",
        "validation_datagen = ImageDataGenerator( rescale = 1/255)\n",
        "\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "VALIDATION_DIR , batch_size= 20 , class_mode = 'binary' , target_size=(150,150))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22498 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyS4n53w7DxC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92bb93e3-83ab-4d7b-88e2-4ad9013209bf"
      },
      "source": [
        "history = model.fit(train_generator ,\n",
        "                    steps_per_epoch=100, \n",
        "                    epochs=100, \n",
        "                    verbose=2,validation_steps=50,\n",
        "                    validation_data=validation_generator , callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.3449 - accuracy: 0.8655 - val_loss: 5.6572e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "100/100 - 24s - loss: 0.2184 - accuracy: 0.9120 - val_loss: 6.4348e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "100/100 - 24s - loss: 0.2366 - accuracy: 0.9170 - val_loss: 1.6283e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "100/100 - 24s - loss: 0.2075 - accuracy: 0.9190 - val_loss: 5.5547e-09 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "100/100 - 24s - loss: 0.2231 - accuracy: 0.9165 - val_loss: 1.0316e-08 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "100/100 - 24s - loss: 0.2218 - accuracy: 0.9220 - val_loss: 1.3082e-08 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "100/100 - 24s - loss: 0.1832 - accuracy: 0.9374 - val_loss: 1.9001e-09 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "100/100 - 23s - loss: 0.2029 - accuracy: 0.9270 - val_loss: 8.8861e-10 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "100/100 - 24s - loss: 0.2122 - accuracy: 0.9220 - val_loss: 8.1163e-11 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "100/100 - 23s - loss: 0.2058 - accuracy: 0.9294 - val_loss: 2.0658e-10 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "100/100 - 24s - loss: 0.1974 - accuracy: 0.9325 - val_loss: 2.7844e-10 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 - 23s - loss: 0.2134 - accuracy: 0.9290 - val_loss: 4.7906e-11 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "100/100 - 24s - loss: 0.1908 - accuracy: 0.9289 - val_loss: 1.1717e-10 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "100/100 - 23s - loss: 0.1784 - accuracy: 0.9405 - val_loss: 8.6074e-10 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "100/100 - 24s - loss: 0.1881 - accuracy: 0.9280 - val_loss: 3.9292e-11 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "100/100 - 24s - loss: 0.1778 - accuracy: 0.9405 - val_loss: 7.6988e-09 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "100/100 - 24s - loss: 0.1938 - accuracy: 0.9370 - val_loss: 1.4923e-09 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "100/100 - 24s - loss: 0.1740 - accuracy: 0.9425 - val_loss: 8.5468e-11 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "100/100 - 24s - loss: 0.1910 - accuracy: 0.9345 - val_loss: 2.7923e-10 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "100/100 - 24s - loss: 0.1733 - accuracy: 0.9340 - val_loss: 2.9632e-11 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "100/100 - 24s - loss: 0.1661 - accuracy: 0.9385 - val_loss: 1.3812e-09 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "100/100 - 24s - loss: 0.1718 - accuracy: 0.9360 - val_loss: 1.3108e-12 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "100/100 - 24s - loss: 0.1705 - accuracy: 0.9450 - val_loss: 1.0154e-11 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "100/100 - 24s - loss: 0.1583 - accuracy: 0.9485 - val_loss: 1.5214e-12 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "100/100 - 24s - loss: 0.1576 - accuracy: 0.9475 - val_loss: 5.3381e-15 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "100/100 - 24s - loss: 0.1972 - accuracy: 0.9340 - val_loss: 8.3614e-13 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "100/100 - 24s - loss: 0.1392 - accuracy: 0.9465 - val_loss: 4.8112e-13 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "100/100 - 24s - loss: 0.1934 - accuracy: 0.9310 - val_loss: 1.5032e-11 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "100/100 - 24s - loss: 0.1600 - accuracy: 0.9425 - val_loss: 1.3283e-10 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "100/100 - 24s - loss: 0.1794 - accuracy: 0.9405 - val_loss: 1.1413e-09 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "100/100 - 25s - loss: 0.1582 - accuracy: 0.9385 - val_loss: 3.4684e-12 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "100/100 - 24s - loss: 0.1759 - accuracy: 0.9430 - val_loss: 1.8830e-12 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "100/100 - 25s - loss: 0.1755 - accuracy: 0.9409 - val_loss: 4.2383e-10 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MWZrJN4-65RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b9e0f3d4-97f7-4b7b-c491-e4a4be380d29"
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) \n",
        "\n",
        "\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9d3e12bbfea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXxIdeUGorEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}