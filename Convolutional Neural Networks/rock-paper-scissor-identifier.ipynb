{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# DataSets\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \\\n    -O /tmp/rps.zip\n  \n","execution_count":5,"outputs":[{"output_type":"stream","text":"--2020-08-19 16:08:54--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.31.128, 172.217.204.128, 173.194.216.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.31.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 200682221 (191M) [application/zip]\nSaving to: ‘/tmp/rps.zip’\n\n/tmp/rps.zip        100%[===================>] 191.38M   204MB/s    in 0.9s    \n\n2020-08-19 16:08:55 (204 MB/s) - ‘/tmp/rps.zip’ saved [200682221/200682221]\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget --no-check-certificate \\\n    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip \\\n    -O /tmp/rps-test-set.zip","execution_count":6,"outputs":[{"output_type":"stream","text":"--2020-08-19 16:08:56--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 74.125.31.128, 172.217.203.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 29516758 (28M) [application/zip]\nSaving to: ‘/tmp/rps-test-set.zip’\n\n/tmp/rps-test-set.z 100%[===================>]  28.15M  39.6MB/s    in 0.7s    \n\n2020-08-19 16:08:57 (39.6 MB/s) - ‘/tmp/rps-test-set.zip’ saved [29516758/29516758]\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport zipfile\n\nlocal_zip = '/tmp/rps.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('/tmp/')\nzip_ref.close()\n\nlocal_zip = '/tmp/rps-test-set.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('/tmp/')\nzip_ref.close()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rock_dir = os.path.join('/tmp/rps/rock')\npaper_dir = os.path.join('/tmp/rps/paper')\nscissors_dir = os.path.join('/tmp/rps/scissors')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\nTRAINING_DIR = \"/tmp/rps/\"\ntraining_datagen = ImageDataGenerator(\n      rescale = 1./255,\n\t    rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\nVALIDATION_DIR = \"/tmp/rps-test-set/\"\nvalidation_datagen = ImageDataGenerator(rescale = 1./255)\n\ntrain_generator = training_datagen.flow_from_directory(\n\tTRAINING_DIR,\n\ttarget_size=(150,150),\n\tclass_mode='categorical',\n  batch_size=126\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n\tVALIDATION_DIR,\n\ttarget_size=(150,150),\n\tclass_mode='categorical',\n  batch_size=126\n)\n\nmodel = tf.keras.models.Sequential([\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n\n\nmodel.summary()\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nhistory = model.fit(train_generator, epochs=25, \n                    steps_per_epoch=20, validation_data = validation_generator, \n                    verbose = 1, validation_steps=3)","execution_count":9,"outputs":[{"output_type":"stream","text":"Found 2520 images belonging to 3 classes.\nFound 372 images belonging to 3 classes.\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 148, 148, 64)      1792      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 72, 72, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6272)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 6272)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               3211776   \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 1539      \n=================================================================\nTotal params: 3,473,475\nTrainable params: 3,473,475\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/25\n20/20 [==============================] - 25s 1s/step - loss: 1.2249 - accuracy: 0.3524 - val_loss: 1.0953 - val_accuracy: 0.3333\nEpoch 2/25\n20/20 [==============================] - 24s 1s/step - loss: 1.1039 - accuracy: 0.4139 - val_loss: 0.9527 - val_accuracy: 0.6048\nEpoch 3/25\n20/20 [==============================] - 24s 1s/step - loss: 0.9488 - accuracy: 0.5270 - val_loss: 0.4916 - val_accuracy: 0.6989\nEpoch 4/25\n20/20 [==============================] - 24s 1s/step - loss: 0.9191 - accuracy: 0.6270 - val_loss: 0.4519 - val_accuracy: 0.6828\nEpoch 5/25\n20/20 [==============================] - 23s 1s/step - loss: 0.6688 - accuracy: 0.7016 - val_loss: 0.4120 - val_accuracy: 0.9892\nEpoch 6/25\n20/20 [==============================] - 23s 1s/step - loss: 0.5600 - accuracy: 0.7528 - val_loss: 0.6469 - val_accuracy: 0.6210\nEpoch 7/25\n20/20 [==============================] - 25s 1s/step - loss: 0.4623 - accuracy: 0.7917 - val_loss: 0.1358 - val_accuracy: 0.9892\nEpoch 8/25\n20/20 [==============================] - 24s 1s/step - loss: 0.3779 - accuracy: 0.8413 - val_loss: 0.3034 - val_accuracy: 0.9570\nEpoch 9/25\n20/20 [==============================] - 24s 1s/step - loss: 0.3606 - accuracy: 0.8548 - val_loss: 0.1023 - val_accuracy: 0.9892\nEpoch 10/25\n20/20 [==============================] - 25s 1s/step - loss: 0.3112 - accuracy: 0.8885 - val_loss: 0.0824 - val_accuracy: 0.9704\nEpoch 11/25\n20/20 [==============================] - 23s 1s/step - loss: 0.2367 - accuracy: 0.9123 - val_loss: 0.0402 - val_accuracy: 1.0000\nEpoch 12/25\n20/20 [==============================] - 24s 1s/step - loss: 0.2761 - accuracy: 0.8881 - val_loss: 0.0964 - val_accuracy: 0.9677\nEpoch 13/25\n20/20 [==============================] - 24s 1s/step - loss: 0.1760 - accuracy: 0.9425 - val_loss: 0.0490 - val_accuracy: 0.9839\nEpoch 14/25\n20/20 [==============================] - 24s 1s/step - loss: 0.1682 - accuracy: 0.9413 - val_loss: 0.0308 - val_accuracy: 1.0000\nEpoch 15/25\n20/20 [==============================] - 24s 1s/step - loss: 0.5112 - accuracy: 0.9290 - val_loss: 0.1094 - val_accuracy: 0.9677\nEpoch 16/25\n20/20 [==============================] - 24s 1s/step - loss: 0.0964 - accuracy: 0.9671 - val_loss: 0.0342 - val_accuracy: 0.9839\nEpoch 17/25\n20/20 [==============================] - 24s 1s/step - loss: 0.1105 - accuracy: 0.9619 - val_loss: 0.0258 - val_accuracy: 0.9839\nEpoch 18/25\n20/20 [==============================] - 24s 1s/step - loss: 0.1135 - accuracy: 0.9611 - val_loss: 0.0655 - val_accuracy: 0.9704\nEpoch 19/25\n20/20 [==============================] - 24s 1s/step - loss: 0.1538 - accuracy: 0.9468 - val_loss: 0.0531 - val_accuracy: 0.9812\nEpoch 20/25\n20/20 [==============================] - 24s 1s/step - loss: 0.1299 - accuracy: 0.9552 - val_loss: 0.1140 - val_accuracy: 0.9704\nEpoch 21/25\n20/20 [==============================] - 24s 1s/step - loss: 0.1222 - accuracy: 0.9579 - val_loss: 0.0575 - val_accuracy: 0.9731\nEpoch 22/25\n20/20 [==============================] - 25s 1s/step - loss: 0.0998 - accuracy: 0.9659 - val_loss: 0.2046 - val_accuracy: 0.9113\nEpoch 23/25\n20/20 [==============================] - 24s 1s/step - loss: 0.0806 - accuracy: 0.9706 - val_loss: 0.0560 - val_accuracy: 0.9785\nEpoch 24/25\n20/20 [==============================] - 25s 1s/step - loss: 0.0994 - accuracy: 0.9635 - val_loss: 0.0117 - val_accuracy: 1.0000\nEpoch 25/25\n20/20 [==============================] - 24s 1s/step - loss: 0.0878 - accuracy: 0.9698 - val_loss: 0.0353 - val_accuracy: 0.9785\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}