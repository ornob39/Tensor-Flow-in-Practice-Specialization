{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport zipfile\nimport random\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nimport os\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \n# pre_trained_model.summary()\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","execution_count":2,"outputs":[{"output_type":"stream","text":"--2020-08-19 12:17:55--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\nResolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 172.217.204.128, 173.194.214.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 87910968 (84M) [application/x-hdf]\nSaving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n\n/tmp/inception_v3_w 100%[===================>]  83.84M   117MB/s    in 0.7s    \n\n2020-08-19 12:17:56 (117 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n\nlast layer output shape:  (None, 7, 7, 768)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget --no-check-certificate \\\n    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n    -O \"/tmp/cats-and-dogs.zip\"\n\nlocal_zip = '/tmp/cats-and-dogs.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('/tmp')\nzip_ref.close()\ntry:\n    \n    os.mkdir('/tmp/cats-v-dogs')\n    os.mkdir('/tmp/cats-v-dogs/training')\n    os.mkdir('/tmp/cats-v-dogs/testing')\n    os.mkdir('/tmp/cats-v-dogs/training/cats')\n    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\nexcept OSError:\n    pass\n\ndef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n\n    dataset = []\n    \n    for unitData in os.listdir(SOURCE):\n        data = SOURCE + unitData\n        if (os.path.getsize(data) > 0):\n            dataset.append(unitData)\n        else:\n            print('Skipped ' + unitData)\n            print('Invalid file size! i.e Zero length.')\n    \n    train_data_length = int(len(dataset) * SPLIT_SIZE)\n    test_data_length = int(len(dataset) - train_data_length)\n    shuffled_set = random.sample(dataset, len(dataset))\n    train_set = shuffled_set[0:train_data_length]\n    test_set = shuffled_set[-test_data_length:]\n    \n    for unitData in train_set:\n        temp_train_data = SOURCE + unitData\n        final_train_data = TRAINING + unitData\n        copyfile(temp_train_data, final_train_data)\n    \n    for unitData in test_set:\n        temp_test_data = SOURCE + unitData\n        final_test_data = TESTING + unitData\n        copyfile(temp_train_data, final_test_data)\n\n\n\nCAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\nTRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\nTESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\nDOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\nTRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\nTESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n\nsplit_size = .9\nsplit_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\nsplit_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)","execution_count":3,"outputs":[{"output_type":"stream","text":"--2020-08-19 12:18:33--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\nResolving download.microsoft.com (download.microsoft.com)... 23.36.32.43, 2600:1402:6800:2a7::e59, 2600:1402:6800:283::e59, ...\nConnecting to download.microsoft.com (download.microsoft.com)|23.36.32.43|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 824894548 (787M) [application/octet-stream]\nSaving to: ‘/tmp/cats-and-dogs.zip’\n\n/tmp/cats-and-dogs. 100%[===================>] 786.68M  33.1MB/s    in 26s     \n\n2020-08-19 12:19:00 (30.2 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n\nSkipped 666.jpg\nInvalid file size! i.e Zero length.\nSkipped 11702.jpg\nInvalid file size! i.e Zero length.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self,epoch,logs={}):\n    if (logs.get('accuracy')>0.999):\n      print(\"Reaches 99.9% accuracy. Cancelling training\")\n      self.model.stop_training = True\n\ncallbacks = myCallback()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation = 'relu')(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Dense( 1 , activation = 'sigmoid')(x)\n\nmodel = Model( pre_trained_model.input , x)\n\n\nmodel.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_DIR = '/tmp/cats-v-dogs/training'\ntrain_datagen = ImageDataGenerator( rescale = 1/255,\n                                  rotation_range = 40,\n                                   width_shift_range= 0.2,\n                                   height_shift_range= 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   fill_mode = 'nearest'\n                                  \n                                  )\n\n\ntrain_generator = train_datagen.flow_from_directory(\nTRAINING_DIR , batch_size = 20 , class_mode = 'binary' , target_size = (150,150))\n\nVALIDATION_DIR = '/tmp/cats-v-dogs/testing'\nvalidation_datagen = ImageDataGenerator( rescale = 1/255)\n\n\nvalidation_generator = validation_datagen.flow_from_directory(\nVALIDATION_DIR , batch_size= 20 , class_mode = 'binary' , target_size=(150,150))","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 22499 images belonging to 2 classes.\nFound 2499 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator ,\n                    steps_per_epoch=100, \n                    epochs=20, \n                    verbose=2,validation_steps=50,\n                    validation_data=validation_generator , callbacks=[callbacks])","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-67de3e16026d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_generator ,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     validation_data=validation_generator , callbacks=[callbacks])\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) \n\n\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}